{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2bb33ba-b63d-48b2-9d5e-ac6df7a6def7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|    _1| _2|\n",
      "+------+---+\n",
      "|chetan|  1|\n",
      "|  veer|  2|\n",
      "|   raj|  3|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the pyspark dataframe from python list\n",
    "\n",
    "lst=[('chetan',1),('veer',2),('raj',3)]\n",
    "df=spark.createDataFrame(data=lst)\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab7af059-d005-4dc6-a67d-1c47f8d21a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name| id|\n",
      "+------+---+\n",
      "|chetan|  1|\n",
      "|  veer|  2|\n",
      "|   raj|  3|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst=[('chetan',1),('veer',2),('raj',3)]\n",
    "df=spark.createDataFrame(data=lst,schema=['Name','id'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bea4f03-fd0e-4eea-93f5-c98079f41aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name| id|\n",
      "+------+---+\n",
      "|chetan|  1|\n",
      "|  veer|  2|\n",
      "|   raj|  3|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst=[('chetan',1),('veer',2),('raj',3)]\n",
    "df=spark.createDataFrame(data=lst,schema=('Name string,id int'))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96450c8b-0561-45ed-8577-f07ffa97a81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb3499e6-6824-4e74-aa1c-294bda22ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df from dictionary.\n",
    "\n",
    "df=[{'name':'aman', 'age':33},{'name':'rao', 'age':33},{'name':'naman', 'age':33}]\n",
    "df=spark.createDataFrame(data=df,schema=('Name string, id int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4745f57c-1e10-4d58-814c-13fc7438b6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7429b8-ea3a-4696-b796-388a7ce2c5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77a62177-3db5-4371-a4c3-b436a1806d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc400b3d-08b1-4d34-9305-6c96f0b4dc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7adad47a-c372-47f5-b2a6-84ca4bf0c7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name| id|\n",
      "+------+---+\n",
      "|chetan|  1|\n",
      "|  veer|  2|\n",
      "|   raj|  3|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating schema from rdd\n",
    "lst=[('chetan',1),('veer',2),('raj',3)]\n",
    "rdd=sc.parallelize(lst)\n",
    "rdd.take(3)\n",
    "\n",
    "df=spark.createDataFrame(data=rdd,schema='name string, id int')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "666c93d7-9b38-44ef-9355-833a28a8357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff93ecc-20d9-41b4-90bb-b5ece124113e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f661681a-572e-42bc-88a3-852cc013647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# print(dir(pd))\n",
    "df=pd.DataFrame(data=lst)\n",
    "df\n",
    "type(df)\n",
    "df=spark.createDataFrame(df)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5df40-c738-4fcf-b3a6-37a40adb1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row in pyspark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d04cf6-4385-47ac-b3d3-75160a5c262a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97960ed8-28a2-43c7-bdea-437656488719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.table  used to convert table from hive context to spark in form of dataframe.\n",
    "lst=[('chetan',1),('veer',2),('raj',3)]\n",
    "df=spark.createDataFrame(lst)\n",
    "df.createOrReplaceTempView('lst')\n",
    "a=spark.sql('select * from lst')\n",
    "type(a)\n",
    "\n",
    "df=spark.table('lst')\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea27d8-5488-4529-b597-1085e1086a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb6ccb-ee47-495a-9318-dfdd56ed2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf in spark\n",
    "\n",
    "# You can use udf in dataframe as well as sparksql just you have to register it in sparksql and wrap it in @udf in dataframe.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
